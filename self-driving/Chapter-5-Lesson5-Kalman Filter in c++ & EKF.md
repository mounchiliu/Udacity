## Lesson 5 Kalman Filter in c++ & EKF
- You have already known how apply Kalman filter to estimation problems. But only use it to combine sequential measurements from **one sensor**.

- Actually, it's also possible to use Kalman filters to combine measurements from different sensors, and that's why we use it in sensor fusion

- **EKF** is able to handling more complex **motion models and measurement models**.
![image](https://user-images.githubusercontent.com/47606318/124294318-1d641480-db8a-11eb-8c18-346cce02f34d.png)

### Flowchart of Kalman Filter for fusion with lidar and radar
![image](https://user-images.githubusercontent.com/47606318/124385969-90949480-dd0a-11eb-8e85-d60abce5ae2e.png)

- you have two sensors, a lidar and a radar
- the information provided by these sensors is used to estimate the state of a moving pedestrian
  - this state is represented by a 2D position and a 2D velocity
- each time we receive new measurements from a given sensor, the estimation function is triggered
  - at this point we perform two steps, State Prediction and Measurement Update
  - in the prediction step, we predict the pedestrian state and its covariance
    - we do so by taking into account the elapsed time between the current and the previous observations
- the measurement update step depends on sensor type (**use the new observations to correct our belief about the state of the pedestrian**)
  - there are two cases that we'll see, Laser and Radar
  - if the current measurements are generated by a laser sensor, then we just apply a standard Kalman filter to update the pedestrian's state
  - however, radar measurements involve a nonlinear measurement function
    - so when we receive radar measurements, we use different tweaks to handle the measurement update
    - for instance, we may use Extended Kalman filter equations, which you'll see later



**Q:** but what happens when there are two sensors that observe the same pedestrian? how does that change the Kalman filter?
**ans:**
- actually, we can keep the same processing flow with the difference that each sensor is going to have its **own prediction/update scheme**
- (当不同传感器 measurement 获取不在同一时刻时， update asynchronously, 只是不同传感器的measurement update 不一样)in other words, the belief about the pedestrian's position and velocity is **updated asynchronously** each time new measurement is received **regardless the source sensor**
![image](https://user-images.githubusercontent.com/47606318/124387378-f5eb8400-dd10-11eb-9039-597533e3beec.png)

**Example**
![image](https://user-images.githubusercontent.com/47606318/124387412-2501f580-dd11-11eb-8d68-1931be3cac59.png)

- here the pedestrian state at time  k  is a distribution with its mean  x  and covariance  P 
- let's say we're now at time  k+1 , and we've just received the laser measurement
  - the first thing we do before we look at the measurement update is to make a prediction about where we think the pedestrian from time  k  will be at time  k+1 
  - the second thing we do is the so called measurement update, where we combine the pedestrian's predicted state with the new laser measurement
  - what we now have is a more accurate belief about the pedestrian's position at time  k+1 ; this is what we call the posterior
- now let's imagine that we receive the radar measurement at time  k+2 
  - first, we again predict the pedestrian state from  k+1  to  k+2 
    - note, this prediction for radar is exactly the same function as in the laser case
  - what changes, in this case, is the Measurement Update step
    - as we know, the radar sees the word differently than laser
    - while laser provides measurement in a Cartesian coordinate system, radar provides measurement in a polar coordinate system
    - thus we have to use different measurement update functions specific to radar data, so this is a more detailed view of the Kalman filter
- **we received the measurements from different sensors at each timestamp, and then we make a prediction followed by a measurement update**

![image](https://user-images.githubusercontent.com/47606318/124388009-5085df80-dd13-11eb-8ebb-3d552a4a2c27.png)

**Q:** What should a Kalman Filter do if both the radar and laser measurements arrive at the same time, k+3 ? 

**Hint:** The Kalman filter algorithm predicts -> updates -> predicts -> updates, etc. If two sensor measurements come in simultaneously, the time step between the first measurement and the second measurement would be zero.

**ans:** 
- **Predict** the state to k+3 then use either one of the sensors to update. Then predict the state to k+3 again and update with the other sensor measurement.
- as you saw, the Kalman filter is a two-step process: predict, and then update
- if you receive two measurements simultaneously, you can use this process with either measurement and then repeat the process with the other measurement
  - the order does not matter!
- because we have already run a prediction-update iteration with the first sensor at time  k+3 , **the output of the second prediction at time  k+3  will actually be identical** to the output from the update step with the first sensor
- so, **in theory**, you could **skip the second prediction step** and just run a prediction, update, update iteration

### Kalman filter in c++
The Kalman equation contains many variables, so here is a high level overview to get some intuition about what the Kalman filter is doing.

#### Intuition

**Prediction**
- Let's say we know an object's current position and velocity , which we keep in the x variable. 
- Now one second has passed. We can predict where the object will be one second later because we knew the object position and velocity one second ago; we'll just assume the object kept going at the same velocity.
- The x′=Fx+ν equation does these prediction calculations for us.

- But maybe the object **didn't maintain the exact same velocity**. Maybe the object changed direction, accelerated or decelerated. 
- So when we predict the position one second later, our uncertainty increases. 
- Update uncertainty: P′=FPF^T+Q represents this increase in uncertainty.

- Process noise refers to the uncertainty in the prediction step. 
- We assume the object travels at a constant velocity, but in reality, the object might accelerate or decelerate. 
- The notation ν∼N(0,Q) defines the process noise as a gaussian distribution with mean zero and covariance Q.

**Measuremtn Update**
- Now we get some sensor information that tells where the object is relative to the car. 
- First we compare where we think we are with what the sensor data tells us y=z−Hx′.

- The K matrix, often called the Kalman filter gain, combines the uncertainty of where we think we are P′ with the uncertainty of our sensor measurement R. 
- If our sensor measurements are very uncertain (R is high relative to P'), then the Kalman filter will give more weight to where we think we are: x′
- If where we think we are is uncertain (P' is high relative to R), the Kalman filter will put more weight on the sensor measurement: z.

- Measurement noise refers to uncertainty in sensor measurements. 
- The notationω∼N(0,R) defines the measurement noise as a gaussian distribution with mean zero and covariance R.


**A Note About the State Transition Function: Bu***
- if you go back to the video, you'll notice that the state transition function was first given as **x′=Fx+Bu+ν ** 
- But then  Bu  was crossed out leaving  x′=Fx+ν 

- B is a matrix called the control input matrix and  u is the control vector
- as an example, let's say we were tracking a car and we knew for certain how much the car's motor was going to accelerate or decelerate over time; in other words, we had an equation to model the exact amount of acceleration at any given moment
- Bu would represent the updated position of the car due to the internal force of the motor
- we would use  ν  to represent any random noise that we could not precisely predict like if the car slipped on the road or a strong wind moved the car


- for the Kalman filter lessons, we will **assume that there is no way to measure or know the exact acceleration** of a tracked object
- for example, if we were in an autonomous vehicle tracking a bicycle, pedestrian or another car, we would **not be able to model the internal forces** of the other object; hence, we do not know for certain what the other object's acceleration is
- instead, we will set  Bu=0  and represent acceleration as a random noise with mean  ν
